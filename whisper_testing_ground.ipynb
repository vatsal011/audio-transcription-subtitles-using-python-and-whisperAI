{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "whisper model details\n",
        "\n",
        "Size\t  | Parameters\tEnglish-only model\tMultilingual model\n",
        "--------+--------------------------------------------------\n",
        "tiny\t  | 39 M\t        ✓\t                ✓\n",
        "base\t  | 74 M\t        ✓\t                ✓\n",
        "small\t  | 244 M\t        ✓\t                ✓\n",
        "medium    | 769 M\t        ✓\t                ✓\n",
        "large\t  | 1550 M                              ✓\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "gHWxKEvhImkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-leZ3TNDntC"
      },
      "outputs": [],
      "source": [
        "!pip install -U openai-whisper # for using Whisper AI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import modules\n",
        "import os\n",
        "import whisper\n",
        "from tqdm import tqdm\n",
        "from datetime import timedelta"
      ],
      "metadata": {
        "id": "4rBmegeiIgTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up Whisper client\n",
        "def set_up_whisper_client(model_size):\n",
        "    print(\"Loading whisper model...\")\n",
        "    model = whisper.load_model(model_size)\n",
        "    print(\"Whisper model complete.\")\n",
        "    print(\"-------------------------------------------------\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "OVqFOyo1bxfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the number of wav files in the root folder and its sub-folders\n",
        "def get_file_names_and_count(root_path):\n",
        "    print(\"Getting files names to transcribe...\")\n",
        "    file_name_list = os.listdir(root_path)\n",
        "    number_of_files = len(file_name_list)\n",
        "    print(file_name_list)\n",
        "    print(\"Number of files:\", number_of_files)\n",
        "    print(\"-------------------------------------------------\")\n",
        "    return file_name_list, number_of_files"
      ],
      "metadata": {
        "id": "xJZHquNdcPWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe_audio(model, file_name, file_path, exit_path):\n",
        "    transcribe = model.transcribe(file_path, language=\"hi\", fp16=False, verbose=True, task='translate')\n",
        "    segments = transcribe['segments']\n",
        "\n",
        "    for segment in segments:\n",
        "        start_time = str(0)+str(timedelta(seconds=int(segment['start'])))+',000'\n",
        "        end_time = str(0)+str(timedelta(seconds=int(segment['end'])))+',000'\n",
        "        text = segment['text']\n",
        "        segment_id = segment['id']+1\n",
        "        segment = f\"{segment_id}\\n{start_time} --> {end_time}\\n{text[1:] if text[0] == ' ' else text}\\n\\n\"\n",
        "\n",
        "        srt_file = os.path.join(exit_path, f\"{file_name.split('.')[0]}.srt\")\n",
        "        with open(srt_file, 'a', encoding='utf-8') as srtFile:\n",
        "            srtFile.write(segment)\n",
        "\n",
        "    print(f\"{file_name} transcription complete.\\n\")\n",
        "    return"
      ],
      "metadata": {
        "id": "5XVnbZV-aahE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe_all_audios(root_path, exit_path, file_name_list, number_of_files):\n",
        "    for i in range(number_of_files):\n",
        "        file_name = file_name_list[i]\n",
        "        file_path = os.path.join(root_path, file_name)\n",
        "        transcribe_audio(model, file_name, file_path, exit_path)"
      ],
      "metadata": {
        "id": "_9KL9x9phPtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model size\n",
        "model_size = \"large\"\n",
        "\n",
        "# Define the folder where the wav files are located\n",
        "root_path = \"/content/drive/MyDrive/Colab_Notebooks/input_files\"\n",
        "exit_path = \"/content/drive/MyDrive/Colab_Notebooks/output_files\"\n",
        "\n",
        "# Get file data and generate transcription\n",
        "model = set_up_whisper_client(model_size)\n",
        "file_name_list, number_of_files = get_file_names_and_count(root_path)\n",
        "transcribe_all_audios(root_path, exit_path, file_name_list, number_of_files)\n",
        "\n",
        "print(\"Transcription of all files completed successfully!!!\")\n"
      ],
      "metadata": {
        "id": "s7PMwvbac3bg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}